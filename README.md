# XHDoubanCrawler
---
这是一个简单的豆瓣爬虫，目的是爬取豆瓣电影页面，~~实际目的是初学 NodeJS 上手~~，之后对页面进行分析处理抓取想要的结果。  
## Dependencies
```
"dependencies": {
  "cheerio": "~0.20.0",
  "request": "~2.69.0",
  "pinyin": "~2.7.1",
  "heap": "~0.2.6",
  "mkdirp": "~0.5.1"
}
```  
*	**request**: 网络请求库
*	**cheerio**: 服务器端的 JQuery
*	**heap**: javascript 堆实现
*	**pinyin**: 汉字拼音处理(排序用)
*	**mkdirp**: node.js 新建文件夹模块

## Environment
```
"engines": {
  "node": "0.10.x",
  "npm": "1.3.x"
}
```   
## Application
这个爬虫的爬取策略是，我先选出一组若干个种子 URL 进行爬取，过程中分析每个 URL 的 DOM 结构中的「喜欢这部电影的人也喜欢」列表，再递归爬取。其中关于对 DOM 的处理以及其他页面分析行为，比如排除无效页面，排除电视剧页面等问题请详见代码。另外，这个爬虫还对断点或者网络出现其他情况，比如被服务器`403`禁止访问等进行了优化，记录了断点时刻的各变量，支持从断点时刻重启爬虫(~~针对`403`问题， 我的对策是更换 VPN~~)。所有版本支持某些自定义设置，请在代码头进行调整，比如抓取要求，抓取数目，影片排列顺序(按名字，年份，导演，评分)等等。  
### v0.0.1
这个版本是最初写的，其中包括 `app_dfs.js` 和 `app_bfs.js`，分别是采取了深度优先和宽度优先的策略来实现爬取功能。这个版本没有将爬取和页面分析以及结果输出分开，三个部分放在了一起，比较混乱。  
### v0.0.2  
这个版本包括 `app_crawl_dfs.js` 和 `app_crawl_bfs.js`，分别是采取了深度优先和宽度优先的策略来实现爬取功能。这个版本将爬取和页面分析功能剥离开来，`parse.js` 功能为结果输出。被爬取的有效(满足要求，比如评分大于8分)页面被存储在本地文件夹中。  
### v0.0.3  
这个版本文件和 `v0.2` 内容一致，只是我将页面分析功能放进了 `parse.js` 中，因此 `app_crawl_dfs.js` 和 `app_crawl_bfs.js` 只负责爬取足够多的页面并保存到本地，而 `parse.js` 再对这些页面进行分析和输出结果。这样一来，爬取可以做到最有效率，分析可以满足更多自定义要求。  
## Results
我把一部分的爬取结果放到了这个仓库，请下载仓库并在 `#results` 中查看。 另外，我将2000部8分以上的电影进行了处理，放到了[这个页面](http://xiaohuang.rocks/xhdoubancrawler/)，其中有一个随机推荐功能，欢迎点击:  

<a href="http://xiaohuang.rocks/xhdoubancrawler/"><img src="./xhdoubancrawler-gh-pages/sources/bg.jpg" width="100%"></a>

